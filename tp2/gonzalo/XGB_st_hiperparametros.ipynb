{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import datetime as dat\n",
    "import matplotlib as plt\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = pd.read_csv('../xgb/training_set_st.csv').set_index('ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python2.7/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "features = matriz.iloc[:,:-1]\n",
    "labels = matriz.iloc[:,-1]\n",
    "data_dmatrix = xgb.DMatrix(data=features,label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = \\\n",
    "    train_test_split(features, labels, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85262.17492114814\n",
      "num_boost_round50\n",
      "n_jobs10\n",
      "85232.98060282394\n",
      "85189.3514724003\n",
      "85151.77400500541\n",
      "85134.26437683376\n",
      "85119.98393911473\n",
      "85106.76115096452\n",
      "colsample_bytree0.6\n",
      "n_folds10\n",
      "alpha10.0\n",
      "learning_rate0.055\n",
      "84995.86214597207\n",
      "84891.41795519897\n",
      "84795.07586732089\n",
      "84691.53731384588\n",
      "84619.30003287442\n",
      "84612.75558994262\n",
      "84594.07384584147\n",
      "84588.70991847456\n",
      "max_depth23\n",
      "gamma10.0\n",
      "num_boost_round50\n",
      "n_jobs10\n",
      "84553.64947432412\n",
      "colsample_bytree0.55\n",
      "n_folds10\n",
      "alpha10.0\n",
      "84546.36712011929\n",
      "84496.09008931789\n",
      "learning_rate0.045\n",
      "max_depth23\n",
      "gamma10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': [10.0, 0.1],\n",
       " 'colsample_bytree': [0.5499999999999999, 0.05],\n",
       " 'gamma': [10.0, 0.5],\n",
       " 'learning_rate': [0.045000000000000005, 0.005],\n",
       " 'max_depth': [23, 1],\n",
       " 'n_folds': [10, 1],\n",
       " 'n_jobs': [10, 1],\n",
       " 'num_boost_round': [50, 5]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        'colsample_bytree': [0.55, 0.05],\n",
    "        'learning_rate': [0.045, 0.005],\n",
    "        'max_depth': [23, 1],\n",
    "        'alpha': [10, 0.1],\n",
    "        'num_boost_round': [50, 5],\n",
    "        'gamma': [10, 0.5],\n",
    "        'n_jobs': [10, 1],\n",
    "        #'n_estimators': [90, 10],\n",
    "        'n_folds': [10, 1],\n",
    "        }\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', max_depth = params['max_depth'][0], learning_rate = params['learning_rate'][0], \\\n",
    "                          #n_estimators = params['n_estimators'][0], \\\n",
    "                          n_jobs = params['n_jobs'][0], gamma = params['gamma'][0], \\\n",
    "                          colsample_bytree = params['colsample_bytree'][0], alpha = params['alpha'][0], \\\n",
    "                          num_boost_round = params['num_boost_round'][0], n_folds = params['n_folds'][0])\n",
    "\n",
    "xg_reg.fit(train_features,train_labels)\n",
    "predicted_labels = xg_reg.predict(test_features)\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, predicted_labels))\n",
    "print(rmse)\n",
    "best_score = rmse\n",
    "best_try = params.copy()\n",
    "def probar_sumar(hiperparametro):\n",
    "    params[hiperparametro][0] += params[hiperparametro][1]\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:linear', max_depth = params['max_depth'][0], learning_rate = params['learning_rate'][0], \\\n",
    "                              #n_estimators = params['n_estimators'][0], \\\n",
    "                              n_jobs = params['n_jobs'][0], gamma = params['gamma'][0], \\\n",
    "                              colsample_bytree = params['colsample_bytree'][0], alpha = params['alpha'][0], \\\n",
    "                              num_boost_round = params['num_boost_round'][0], n_folds = params['n_folds'][0])\n",
    "    xg_reg.fit(train_features,train_labels)\n",
    "    predicted_labels = xg_reg.predict(test_features)\n",
    "    rmse = np.sqrt(mean_squared_error(test_labels, predicted_labels))\n",
    "    return rmse\n",
    "    \n",
    "def probar_restar(hiperparametro):\n",
    "    params[hiperparametro][0] -= params[hiperparametro][1]\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:linear', max_depth = params['max_depth'][0], learning_rate = params['learning_rate'][0], \\\n",
    "                              #n_estimators = params['n_estimators'][0], \\\n",
    "                              n_jobs = params['n_jobs'][0], gamma = params['gamma'][0], \\\n",
    "                              colsample_bytree = params['colsample_bytree'][0], alpha = params['alpha'][0], \\\n",
    "                              num_boost_round = params['num_boost_round'][0], n_folds = params['n_folds'][0])\n",
    "    xg_reg.fit(train_features,train_labels)\n",
    "    predicted_labels = xg_reg.predict(test_features)\n",
    "    rmse = np.sqrt(mean_squared_error(test_labels, predicted_labels))\n",
    "    return rmse\n",
    "    \n",
    "for i in range(2):\n",
    "    for hiperparam in params:\n",
    "        mejor = True\n",
    "        while(mejor):\n",
    "            score = probar_sumar(hiperparam)\n",
    "            mejor = ( score < best_score)\n",
    "            if mejor:\n",
    "                best_score = score\n",
    "                print(best_score)\n",
    "        params[hiperparam][0] -= params[hiperparam][1]\n",
    "        \n",
    "        mejor = True\n",
    "        while(mejor):\n",
    "            score = probar_restar(hiperparam)\n",
    "            mejor = ( score < best_score)\n",
    "            if mejor:\n",
    "                best_score = score\n",
    "                print(best_score)\n",
    "        params[hiperparam][0] += params[hiperparam][1]\n",
    "        print(hiperparam + str(params[hiperparam][0]))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [10, 0.1],\n",
       " 'colsample_bytree': [0.3, 0.05],\n",
       " 'gamma': [10, 0.5],\n",
       " 'learning_rate': [0.055, 0.005],\n",
       " 'max_depth': [15, 1],\n",
       " 'n_estimators': [300, 10],\n",
       " 'n_folds': [10, 1],\n",
       " 'n_jobs': [10, 1],\n",
       " 'num_boost_round': [50, 5]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
